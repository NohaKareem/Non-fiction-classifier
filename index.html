<!DOCTYPE html>
<html>

<head>
  <script src="https://cdn.jsdelivr.net/npm/p5@1.2.0/lib/p5.min.js"></script>
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <script type="text/javascript" src="https://www.gstatic.com/charts/loader.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js@2.8.0"></script>
  <meta name="viewport" content="initial-scale=1.0, width=device-width">
  <link href="https://fonts.googleapis.com/css2?family=DM+Sans&display=swap" rel="stylesheet">
  <script src="https://unpkg.com/ml5@0.4.2/dist/ml5.min.js"></script>
  <link href="css/main.css" rel="stylesheet" type="text/css">
  <meta charset="utf-8" />
  <title>Non-fiction Classifier</title>
</head>

<body>
  <h1>Judging a (non-fiction) book by its cover</h1>
  <p class="intro">
    <span class="bold">About:</span> This is a classifier that classifies non-fiction book covers, using <a
      href="https://teachablemachine.withgoogle.com/">Teachable Machine</a>. This is built to test how reliably a
    learning algorithm could detect a non-fiction book category by its cover.

    <br><br>
    <span class="bold">How to use:</span> To have the classifier judge your book by its cover, hold up your book to your
    device's camera. Try experimenting with the positioning, note that the the classifier is reading everything in your
    screen, so be mindful of how you position your book, and how it's being cropped. Also, you'll need to turn
    on camera permissions for this to work.
  </p>
  <div class="bookCon">
    <div id="canvasCon">
      <script src="js/tensorflow.js"></script>
    </div>
    <img src="images/books.png" alt="A stack of books">
  </div>
  <!-- results -->
  <div>
    <h1 id="label"></h1>
    <div class="resultsConCon">
      <div class="process resultsCon">
        <ul>
        </ul>
      </div>
    </div>
    <canvas id="predictionsChart"></canvas>
    <div class="info">
      <div class="trainaingSettings">
        <h2>Training Settings</h2>
        <p>
          <span class="bold">Epochs:</span> 70 <br>
          <span class="bold">Batch Size:</span> 16 <br>
          <span class="bold">Learning Rate:</span> 0.001 <br>
        </p>
      </div>
      <div class="trainingData">
        <h2>Training Dataset Size*</h2>
        <p class="trainSize">
          <span class="bold">Biography/memoir:</span> 45 <br>
          <span class="bold">Career, business& entrepreneurship:</span> 45 <br>
          <span class="bold">Food& cookbooks:</span> 45 <br>
          <span class="bold">Nature:</span> 45 <br>
          <span class="bold">Personal growth& development:</span> 45 <br>
          <span class="bold">Tech& Coding:</span> 45 <br>
          <span class="bold">Other:</span> 45 <br>
          * all training images were that of English books
        </p>
      </div>
    </div>
    <div class="process">
      <h2>Training Notes</h2>
      <p>A total of 315 images were trained, across 7 categories, with 45 samples each. An 'Other' category was provided
        to categorize other non-fiction genres. It included a selection of non-fiction topics from beauty and writing to
        crafts and woodwork. Ideally, more training samples would be provided, encompassing more diversity and thus
        providing a more nuanced learning model.
        <br><br>
        On default settings epochs 50, batch size 16, and learning rate 0.001, the prediction accuracy rates were above
        average for biography/memoirs, food&
        cookbooks and nature. All other categories seemed to have less than average accuracy when tested (with a sample
        size of 7 books).
        <br><br>
        The confusion matrix reflected, among other things, a confusion in nature and technology& code (this makes sense
        as some books in the tech& coding training dataset showcase nature illustration such as of birds and reptiles).
        The loss per epoch (reflecting accuracy where the closer the loss value is to 0, the better) for test dataset is
        at 1.5 or higher (up to 2.5) as epochs increase.
        <br><br>
        Most importantly, the loss curve (or training curve) was indefinitely decreasing, while the test loss curve
        (also known as validation) was indefinitely increasing, suggesting a model underfit (<a
          href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/">ref</a>).
        <br><br>
        From there, a number of parameter changes were experimented with and it was noticed that a higher epoch size,
        with this dataset, would increase accuracy in some of the classes possibly at the expense of underfitting the
        remainder ones.
        <br><br>
        For an overall reasonable classifier given the training dataset at hand, the settings above (70 epochs, batch
        size of 16 and learning rate of 0.001) was provided. This model offered the highest rate of classes with above
        average accuracy (more details in <a
          href="https://www.notion.so/Teachable-Machine-training-log-ad96d92170a64623a05abf3d5e460ad6">this log</a>),
        without severely underfitting any of the other classes.
        <br><br>
        Overall, lower accuracy classes reflect the low dataset that doesn't reinforce the intra-diversity. A common
        case across different training iterations was with the personal growth class, which included a wide breadth of
        sub-topics, such as productivity, psychology, decision making and more. On the other hand, higher
        accuracy classes reflect higher sample similarity and thus higher accuracy rates for the given test dataset. A
        common case was biographies and memoirs, which tend to have a person's photo on the cover.
        <br><br>
        <span class="bold">Room for growth:</span> For a better classifier, a wider training dataset could be provided.
        Also, some classes may require more training datasets than others (such as the 'Other' category, encompassing a
        wide breadth of topics), or the class could be divided into multiple classes, each of which would be populated
        with a sufficient amount of training images.
        <br><br>
        For more details on training model iterative testing and accuracy results (including confusion matrix for
        iteration mentioned above, and more), consider <a
          href="https://www.notion.so/Teachable-Machine-training-log-ad96d92170a64623a05abf3d5e460ad6">this log</a>.
      </p>
    </div>
  </div>
</body>

</html>